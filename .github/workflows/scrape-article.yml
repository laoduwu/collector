name: Scrape Article

on:
  repository_dispatch:
    types: [scrape-article]
  workflow_dispatch:
    inputs:
      article_url:
        description: 'Article URL to scrape'
        required: true
        type: string

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install system dependencies
        run: |
          # 更新包列表
          sudo apt-get update

          # 安装Chrome依赖
          sudo apt-get install -y \
            wget \
            gnupg \
            ca-certificates \
            fonts-liberation \
            libasound2 \
            libatk-bridge2.0-0 \
            libatk1.0-0 \
            libc6 \
            libcairo2 \
            libcups2 \
            libdbus-1-3 \
            libexpat1 \
            libfontconfig1 \
            libgbm1 \
            libgcc1 \
            libglib2.0-0 \
            libgtk-3-0 \
            libnspr4 \
            libnss3 \
            libpango-1.0-0 \
            libpangocairo-1.0-0 \
            libstdc++6 \
            libx11-6 \
            libx11-xcb1 \
            libxcb1 \
            libxcomposite1 \
            libxcursor1 \
            libxdamage1 \
            libxext6 \
            libxfixes3 \
            libxi6 \
            libxrandr2 \
            libxrender1 \
            libxss1 \
            libxtst6 \
            lsb-release \
            xdg-utils

          # 安装Chrome
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

          # 验证安装
          google-chrome --version

      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraper
        env:
          # 从repository_dispatch或workflow_dispatch获取URL
          ARTICLE_URL: ${{ github.event.client_payload.url || inputs.article_url }}
          # 飞书配置
          FEISHU_APP_ID: ${{ secrets.FEISHU_APP_ID }}
          FEISHU_APP_SECRET: ${{ secrets.FEISHU_APP_SECRET }}
          FEISHU_VERIFICATION_TOKEN: ${{ secrets.FEISHU_VERIFICATION_TOKEN }}
          FEISHU_ENCRYPT_KEY: ${{ secrets.FEISHU_ENCRYPT_KEY }}
          FEISHU_KNOWLEDGE_SPACE_ID: ${{ secrets.FEISHU_KNOWLEDGE_SPACE_ID }}
          FEISHU_UNORGANIZED_FOLDER_NAME: ${{ secrets.FEISHU_UNORGANIZED_FOLDER_NAME || '待整理' }}
          # Jina AI配置
          JINA_API_KEY: ${{ secrets.JINA_API_KEY }}
          JINA_MODEL: ${{ secrets.JINA_MODEL || 'jina-embeddings-v2-base-zh' }}
          SIMILARITY_THRESHOLD: ${{ secrets.SIMILARITY_THRESHOLD || '0.7' }}
          # GitHub配置
          GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}
          GITHUB_REPO: ${{ secrets.GITHUB_REPO }}
          GITHUB_BRANCH: ${{ secrets.GITHUB_BRANCH || 'main' }}
          # 日志配置
          LOG_LEVEL: ${{ secrets.LOG_LEVEL || 'INFO' }}
        run: |
          cd src
          python main.py "$ARTICLE_URL"

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-logs
          path: |
            *.log
            logs/
          retention-days: 7
