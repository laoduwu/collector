name: Scrape Article

on:
  repository_dispatch:
    types: [scrape-article]
  workflow_dispatch:
    inputs:
      article_url:
        description: 'Article URL to scrape'
        required: true
        type: string

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install Chrome
        run: |
          # 使用官方脚本安装Chrome（兼容Ubuntu 24.04）
          wget -q https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo apt-get update
          sudo apt-get install -y ./google-chrome-stable_current_amd64.deb
          rm google-chrome-stable_current_amd64.deb

          # 验证安装
          google-chrome --version

      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraper
        env:
          # 从repository_dispatch或workflow_dispatch获取URL
          ARTICLE_URL: ${{ github.event.client_payload.url || inputs.article_url }}
          # 飞书配置
          FEISHU_APP_ID: ${{ secrets.FEISHU_APP_ID }}
          FEISHU_APP_SECRET: ${{ secrets.FEISHU_APP_SECRET }}
          FEISHU_VERIFICATION_TOKEN: ${{ secrets.FEISHU_VERIFICATION_TOKEN }}
          FEISHU_ENCRYPT_KEY: ${{ secrets.FEISHU_ENCRYPT_KEY }}
          FEISHU_KNOWLEDGE_SPACE_ID: ${{ secrets.FEISHU_KNOWLEDGE_SPACE_ID }}
          FEISHU_UNORGANIZED_FOLDER_NAME: ${{ secrets.FEISHU_UNORGANIZED_FOLDER_NAME || '待整理' }}
          # Jina AI配置
          JINA_API_KEY: ${{ secrets.JINA_API_KEY }}
          JINA_MODEL: ${{ secrets.JINA_MODEL || 'jina-embeddings-v2-base-zh' }}
          SIMILARITY_THRESHOLD: ${{ secrets.SIMILARITY_THRESHOLD || '0.7' }}
          # GitHub配置（图片托管）
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
          IMAGE_REPO: ${{ secrets.IMAGE_REPO }}
          IMAGE_BRANCH: ${{ secrets.IMAGE_BRANCH || 'main' }}
          # 日志配置
          LOG_LEVEL: ${{ secrets.LOG_LEVEL || 'INFO' }}
          # Python路径配置
          PYTHONPATH: ${{ github.workspace }}/src
        run: |
          cd src
          python main.py "$ARTICLE_URL"

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-logs
          path: |
            *.log
            logs/
          retention-days: 7
